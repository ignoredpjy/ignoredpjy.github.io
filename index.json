[{"content":"索引（B+树） 提到mysql索引，就不会不提：B+ 树 、B-树 和 红黑树\nInnoDB 是最常用的存储引擎，B+树是InnoDB默认的索引机制。\nB+树 VS B-树 VS 红黑树 磁盘知识 分页：\n现代操作系统都使用虚拟内存来印射到物理内存，内存大小有限且价格昂贵，所以数据的持久化是在磁盘上。虚拟内存、物理内存、磁盘都使用页作为内存读取的最小单位。一般一页为4KB（8个扇区，每个扇区512B，8*512B=4KB）\n局部性原理：\n时间局部性：一个被引用过一次的内存位置很可能在不远的将来再次被多次引用。 空间局部性：当一个数据被用到时，其附近的数据也通常会马上被使用。程序运行期间所需要的数据通常比较集中。 顺序局部性（Order Locality）：在典型程序中，除转移类指令外，大部分指令是顺序进行的。顺序执行和非顺序执行的比例大致是5:1。此外，对大型数组访问也是顺序的。 磁盘IO速度 \u0026amp; 预读\n速度：CPU \u0026raquo; Cache \u0026raquo;\u0026gt; 主内存 \u0026raquo;\u0026raquo; 磁盘， 磁盘读取的速度远小于内存，所以尽量减少 I/O 次数是提高效率的关键。\n考虑到磁盘IO是非常高昂的操作，计算机操作系统做了一些优化，IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，因为局部性原理。而且即使只需要读取一个字节，磁盘也会读取一页的数据。\n查找树知识 二叉平衡树/二叉查找树\n平衡树是为了防止二叉查找树退化为链表，而红黑树在维持平衡以确保 O(log2(n)) 的同时，不需要频繁着调整树的结构；\nAVL树是最先发明的自平衡二叉查找树，AVL树中任何节点的两个子树的高度最大差别为1，所以它也被称为高度平衡树。通过旋转来实现自平衡 2-3 树，要求严格的平衡，通过允许3节点，减少自平衡次数 红黑树，不要求严格平衡，减少自平衡次数 b+/b-树\nB树/B-树：所有节点存储数据和指针(索引)；\nB+树\n非叶子节点存储指针 (索引)，叶子节点存储数据； 每个叶子节点有一个指针指向下一个节点，构成一个有序链表 为什么不使用二叉树/红黑树，使用B+树 单拎出来一点，就已经足够否决的了\n**为磁盘而生：**二叉树无法使用磁盘预读功能 , B树专门为磁盘读取而设计，B树的节点大小与磁盘页大小相匹配（InnoDB中页的大小 默认为 16 KB。） **更少的 IO 次数：**树的深度也会影响查询的效率，随着数据量增加，二叉树深度增长飞快，会造成查询时磁盘IO频繁读写，（B+树高度通常不超过3+1） **额外的平衡开销：**二叉树一次插入+平衡的过程，会涉及大量的磁盘I/O操作 更适于范围查询：二叉树存储在磁盘中，范围查询的效率极低，基本不支持范围查询 为什么不使用B-树，使用B+树 B+树非叶子节点仅存储索引不存储data，这样一个节点就可以存储更多的索引，可以使得B+树相对B树来说更矮（IO次数就是树的高度），所以I/O 次数更少\nB+树所有叶子节点构成一个 有序链表，按主键排序来遍历全部记录，能更好支持范围查找和区间查找。而B树每个节点都可能查找到数据，相邻的元素可能在不同节点上，在内存中不相邻，所以范围查找时需要在叶子节点和子节点不停的往返移动，效率较低且不稳定\n文件系统使用B-树，mongoDB使用B-树：\nMongoDB 是一种 nosql，也存储在磁盘上，被设计用在 数据模型简单，性能要求高的场合。性能要求高，看看B/B+树的区别第一点：\nB+树内节点不存储数据，所有 data 存储在叶节点导致查询时间复杂度固定为 log n。而B-树查询时间复杂度不固定，与 key 在树中的位置有关，最好为O(1)\n我们说过，尽可能少的磁盘 IO 是提高性能的有效手段。MongoDB 是聚合型数据库，而 B-树恰好 key 和 data 域聚合在一起。\n为什么不使用Hash、SkipList 待续\n页内查询 使用的是二分查找\nInnoDB的页结构：表头槽数组+最小值+最大值：列链表\n通过最小最大是否跳过该页，通过二分确定索引所在的槽，每个槽最多8个列数据，直接遍历\n细节待续\n页分裂 InnoDB(聚簇索引)的主键值最好是有序的，不仅能充分使用到索引，还尽可能避免了页分裂；否则就必须进行页分裂来保证索引的逻辑正确性； InnoDB 的主键，尽量使用连续增长的值，而不是随机值(比如随机字符串或UUID), 否则可能产生大量的页分裂； InnoDB的B+树索引注意事项：根页面的位置万年不动，一个页面最少存储2条记录。 原理待续\n索引代价 空间上的代价\n这个是显而易见的，每建立一个索引都要为它建立一棵 B+ 树，每一棵 B+ 树的每一个节点都是一个数据页， 一个页默认会占用 16KB 的存储空间，一棵很大的 B+ 树由许多数据页组成，那可是很大的一片存储空间呢。\n时间上的代价\n每次对表中的数据进行增、删、改操作时，都需要去修改各个 B+ 树索引。而且我们讲过， B+ 树每层节点都 是按照索引列的值从小到大的顺序排序而组成了双向链表。不论是叶子节点中的记录，还是内节点中的记录 （也就是不论是用户记录还是目录项记录）都是按照索引列的值从小到大的顺序而形成了一个单向链表。而 增、删、改操作可能会对节点和记录的排序造成破坏，所以存储引擎需要额外的时间进行一些记录移位，页 面分裂、页面回收啥的操作来维护好节点和记录的排序。如果我们建了许多索引，每个索引对应的 B+ 树都 要进行相关的维护操作，这还能不给性能拖后腿么？\n回表\n最好在查询列表里只包含索引列，避免回表\n需要回表的记录越多，使用二级索引的性能就越低，甚至可能不如全表查询，由查询优化器选择。\n优化索引 explain各个字段代表的意思\nid ：select查询的序列号，包含一组数字，表示查询中执行select子句或操作表的顺序\nselect_type ：查询类型 或者是 其他操作类型，单表简单、父子查询\nSIMPLE、UNION、PRIMARY、SUBQUERY、UNION RESULT\ntable ：正在访问哪个表\npartitions ：匹配的分区\ntype ：访问的类型\npossible_keys ：显示可能应用在这张表中的索引，一个或多个，但不一定实际使用到\nkey ：实际使用到的索引，如果为NULL，则没有使用索引\nkey_len ：表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度\nref ：显示索引的哪一列被使用了，如果可能的话，是一个常数，哪些列或常量被用于查找索引列上的值\nrows ：根据表统计信息及索引选用情况，大致估算出找到所需的记录所需读取的行数\nfiltered ：查询的表行占表的百分比\nExtra ：包含不适合在其它列中显示但十分重要的额外信息\ntype\nNULL \u0026gt; system \u0026gt; const \u0026gt; eq_ref \u0026gt; ref \u0026gt; ref_or_null \u0026gt; index_merge \u0026gt; range \u0026gt; index \u0026gt; ALL\nNULL MySQL能够在优化阶段分解查询语句，在执行阶段用不着再访问表或索引\nSYSTEM 表只有一行记录（等于系统表），这是const类型的特列，平时不大会出现，可以忽略。\nconst 表示通过索引一次就找到了，const用于比较primary key或uique索引，因为只匹配一行数据，所以很快，如主键置于where列表中，MySQL就能将该查询转换为一个常量。\neq_ref 用于联表查询的情况，按联表的主键或唯一键联合查询。\n多表join时，对于来自前面表的每一行，在当前表中只能找到一行。这可能是除了system和const之外最好的类型。当主键或唯一非NULL索引的所有字段都被用作join联接时会使用此类型。\nref 可以用于单表扫描或者连接。如果是连接的话，驱动表的一条记录能够在被驱动表中通过非唯一（主键）属性所在索引中匹配多行数据，或者是在单表查询的时候通过非唯一（主键）属性所在索引中查到一行数据。\nref_or_null 类似ref，但是可以搜索值为NULL的行\nindex_merge 表示查询使用了两个以上的索引，最后取交集或者并集，常见and ，or的条件使用了不同的索引，官方排序这个在ref_or_null之后，但是实际上由于要读取多个索引，性能可能大部分时间都不如range。\nrange 索引范围查询，常见于使用 =, \u0026lt;\u0026gt;, \u0026gt;, \u0026gt;=, \u0026lt;, \u0026lt;=, IS NULL, \u0026lt;=\u0026gt;, BETWEEN, IN()或者like等运算符的查询中。\nindex index只遍历索引树，通常比All快。因为，索引文件通常比数据文件小，也就是虽然all和index都是读全表，但index是从索引中读取的，而all是从硬盘读的。\nALL 如果一个查询的type是All,并且表的数据量很大，那么请解决它！！！\nExtra\nUsing filesort 表示当SQL中有一个地方需要对一些数据进行排序的时候，优化器找不到能够使用的索引，所以只能使用外部的索引排序，外部排序就不断的在磁盘和内存中交换数据，这样就摆脱不了很多次磁盘IO，以至于SQL执行的效率很低。 Using tempporary 表示在对MySQL查询结果进行排序时，使用了临时表 Using index 表示使用了索引，很优秀。 Using where 使用了where但是好像没啥用。 Using join buffer 表明使用了连接缓存,比如说在查询的时候，多表join的次数非常多，那么将配置文件中的缓冲区的join buffer调大一些。 impossible where 筛选条件没能筛选出任何东西 distinct 优化distinct操作，在找到第一匹配的元组后即停止找同样值的动作 optimizer trace\n待续\n索引失效 对索引使用函数、运算、类型转换 like 没有使用左模糊匹配 使用 不等于 !=、\u0026lt;\u0026gt; 使用 index \u0026lt; [] or index \u0026gt; [] 使用 or ，且条件不全为索引 使用 not in 组合索引非最左匹配， 右边失效 order by 使用外部排序 查询结果集超过全表10%（默认值），使用全表扫描 索引（其他） 待续\n倒排索引（全文索引） 自适应Hash索引 hash索引\n缺点：\nHash索引仅能满足=, \u0026lt;\u0026gt;, IN查询，不能使用范围查询， 同时因为数据的存储是没有顺序的，所以在ORDER BY的情况下，还需要对数据重新进行排序。 使用联合索引时，Hash值是针对联合索引建合并后一起来计算Hash值，因此无法对单独的一个键或者几个索引键进行查询。 优点：\n因为Hash索引结构的特点，导致它的检索数据效率非常高，通常只需要O(1)的复杂度，也就是一次就可以完成数据的检索。 虽然Hash索引的使用场景有很多限制，但是优点也很明显，所以Innodb提供了一个自适当Hash索引的功能（Adaptive Hash index）。\n这里的自适应指的是不需要人工来制定，而是系统根据情况来自动完成的。\n那什么情况下才会使用自适应Hash索引呢？如果某个数据经常会访问到，当满足一定条件的时候，就会将这个数据页的地址存放到Hash表中。这样下次查询的时候，就可以直接找到这个页面的所在位置。需要说明的是：\n自适应哈希索引只保存热数据（经常被使用到的数据），并非全表数据。因此数据量并不会很大，可以让自适应Hash放到缓冲池中，也就是InnoDB buffer pool，进一步提升查找效率。 InnoDB中的自适应Hash相当于是“索引的索引”，采用Hash索引存储的是B+树索引中的页面的地址。这也就是为什么可以称自适应Hash为索引的索引。 采用自适应Hash索引目的是可以根据SQL的查询条件加速定位到叶子节点，特别是当B+树比较深的时候，通过自适应Hash索引可以提高数据的检索效率。 自适应Hash采用Hash函数映射到一个哈希表中，所以对于字典类型的数据查找非常方便 哈希表是数组+链表的形式。通过Hash函数可以计算索引键值所对应的bucket（桶）的位置，如果产生Hash冲突，如果产生哈希冲突，就需要遍历链表来解决。 是否开启了自适应Hash，可以通过innodb_adaptive_hash_index变量来查看，比如：mysql\u0026gt; show variables like \u0026lsquo;%adaptive_hash_index\u0026rsquo;; 所以，总结下InnoDB本身不支持Hash，但是提供自适应Hash索引，不需要用户来操作，而是存储引擎自动完成的。自适应Hash也是InnoDB三大关键特性之一，另外两个分别是插入缓冲（Insert Buffer）和二次写(Double Write)。\n空间索引 事务 锁 共享锁\u0026amp;独占锁 表锁、行锁、意向锁 InnoDB中的行锁 记录锁（record lock）\n间隙锁（gap lock）\ngap lock是共享锁，可叠加——死锁因素\nnext-key lock\n隐式锁（insert lock）\n本质为 gap锁\nAUTO-INC 锁\n死锁 MVCC 版本链 ReadView 可能的回表操作 https://juejin.cn/post/6844904017068294152\n待续\nundo log的删除时机 日志 redo undo bin\nmysql server 连接管理 sql执行器 预处理器 ——》优化器 ——》执行器\n查询优化 存储引擎 InnoDB 存储引擎对比 引擎 描述 InnoDB 支持事务、行锁、外键等高级特性，主键聚簇。具有良好的性能和可靠性。MySQL默认的存储引擎。 MyISAM 由ISAM（Indexed Sequential Access Metod）引擎改良，可移植性好，占用空间小，但是表级别的锁使得并发读写性能较差，适用于只有查询或者读多写少的场景，如：服务配置存储等。 Memory 又被叫做：Heap，数据存储在内存中，可靠性较低，一般用于临时表场景使用。另外 InnoDB 也支持内存缓存可以大量甚至全部数据载入内存，所以这个引擎使用场景越来越少了。 CSV 数据通过 CSV(Comma-Separated Values)的格式存储，可读性和可操作性非常好，但是由于数据未经过索引，性能很差，所以一般用于将其他表中的数据导过来用于与其他应用交互。 Archive 支持压缩，无索引，适用于存储大量冷门归档数据。 Blackhole 黑洞，不存储数据，查询也都会返回空。但这也并不代表这个引擎没有实际价值，它虽然不存储数据但是 binlog 还是会有，所以经常用于做为伪从库减轻主库压力或者记录binlog用。 NDB 全称Network DataBase，是一个分布式存储引擎。 Merge 可以用于将一系列 MyISM 抽象为一张表。 Federated 可以将其他远程数据的表映射到本地。 Example 主要是一个 demo，供开发人员学习如何开发一个存储引擎。 各引擎支持的功能特性对比：\nFeature MyISAM Memory InnoDB Archive NDB B树索引 Yes Yes Yes No No 备份/恢复 Yes Yes Yes Yes Yes 分布式集群支持 No No No No Yes 聚簇索引 No No Yes No No 数据压缩 Yes No Yes Yes No 数据缓存 No N/A Yes No Yes 数据加密 Yes Yes Yes Yes Yes 外键 No No Yes No Yes 全文搜索（倒排） Yes No Yes No No 地理空间数据 Yes No Yes Yes Yes 地理空间索引 Yes No Yes No No 散列索引 No Yes No No Yes 索引缓存 Yes N/A Yes No Yes 锁粒度 Table Table Row Row Row MVCC No No Yes No No 冗余存储 (note 1) Yes Limited Yes Yes Yes 存储限制 256TB RAM 64TB None 384EB T树索引 No No No No Yes 事务 No No Yes No Yes 更新数据字典的统计信息 Yes Yes Yes Yes Yes 注：关于存储限制虽然上限都很高，但是将数据都存储在一个文件的引擎会受操作系统的文件大小限制（TB级别）。\nmysql可以在创建表时，为表单独设置存储引擎\nExample，创建一个 MyISAM 的表：\n1 2 3 4 create table if not exists people ( id int primary key auto_increment, name varchar(40) null, ) comment \u0026#39;存储人物信息\u0026#39; engine=\u0026#39;myisam; Buffer Pool LRU-List、Free-List、Flush-List\n三大特性 插入缓冲 Insert Buffer\n二次写 Double Write\n自适应哈希索引（adaptive hash index）\n","permalink":"https://ignoredpjy.github.io/posts/study/mysql%E5%8E%9F%E7%90%86/","summary":"索引（B+树） 提到mysql索引，就不会不提：B+ 树 、B-树 和 红黑树\nInnoDB 是最常用的存储引擎，B+树是InnoDB默认的索引机制。\nB+树 VS B-树 VS 红黑树 磁盘知识 分页：\n现代操作系统都使用虚拟内存来印射到物理内存，内存大小有限且价格昂贵，所以数据的持久化是在磁盘上。虚拟内存、物理内存、磁盘都使用页作为内存读取的最小单位。一般一页为4KB（8个扇区，每个扇区512B，8*512B=4KB）\n局部性原理：\n时间局部性：一个被引用过一次的内存位置很可能在不远的将来再次被多次引用。 空间局部性：当一个数据被用到时，其附近的数据也通常会马上被使用。程序运行期间所需要的数据通常比较集中。 顺序局部性（Order Locality）：在典型程序中，除转移类指令外，大部分指令是顺序进行的。顺序执行和非顺序执行的比例大致是5:1。此外，对大型数组访问也是顺序的。 磁盘IO速度 \u0026amp; 预读\n速度：CPU \u0026raquo; Cache \u0026raquo;\u0026gt; 主内存 \u0026raquo;\u0026raquo; 磁盘， 磁盘读取的速度远小于内存，所以尽量减少 I/O 次数是提高效率的关键。\n考虑到磁盘IO是非常高昂的操作，计算机操作系统做了一些优化，IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，因为局部性原理。而且即使只需要读取一个字节，磁盘也会读取一页的数据。\n查找树知识 二叉平衡树/二叉查找树\n平衡树是为了防止二叉查找树退化为链表，而红黑树在维持平衡以确保 O(log2(n)) 的同时，不需要频繁着调整树的结构；\nAVL树是最先发明的自平衡二叉查找树，AVL树中任何节点的两个子树的高度最大差别为1，所以它也被称为高度平衡树。通过旋转来实现自平衡 2-3 树，要求严格的平衡，通过允许3节点，减少自平衡次数 红黑树，不要求严格平衡，减少自平衡次数 b+/b-树\nB树/B-树：所有节点存储数据和指针(索引)；\nB+树\n非叶子节点存储指针 (索引)，叶子节点存储数据； 每个叶子节点有一个指针指向下一个节点，构成一个有序链表 为什么不使用二叉树/红黑树，使用B+树 单拎出来一点，就已经足够否决的了\n**为磁盘而生：**二叉树无法使用磁盘预读功能 , B树专门为磁盘读取而设计，B树的节点大小与磁盘页大小相匹配（InnoDB中页的大小 默认为 16 KB。） **更少的 IO 次数：**树的深度也会影响查询的效率，随着数据量增加，二叉树深度增长飞快，会造成查询时磁盘IO频繁读写，（B+树高度通常不超过3+1） **额外的平衡开销：**二叉树一次插入+平衡的过程，会涉及大量的磁盘I/O操作 更适于范围查询：二叉树存储在磁盘中，范围查询的效率极低，基本不支持范围查询 为什么不使用B-树，使用B+树 B+树非叶子节点仅存储索引不存储data，这样一个节点就可以存储更多的索引，可以使得B+树相对B树来说更矮（IO次数就是树的高度），所以I/O 次数更少\nB+树所有叶子节点构成一个 有序链表，按主键排序来遍历全部记录，能更好支持范围查找和区间查找。而B树每个节点都可能查找到数据，相邻的元素可能在不同节点上，在内存中不相邻，所以范围查找时需要在叶子节点和子节点不停的往返移动，效率较低且不稳定\n文件系统使用B-树，mongoDB使用B-树：\nMongoDB 是一种 nosql，也存储在磁盘上，被设计用在 数据模型简单，性能要求高的场合。性能要求高，看看B/B+树的区别第一点：","title":"mysql原理"},{"content":"Spring中七种事务传播行为 事务传播行为类型 说明 PROPAGATION_REQUIRED 如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。 PROPAGATION_SUPPORTS 支持当前事务，如果当前没有事务，就以非事务方式执行。 PROPAGATION_MANDATORY 使用当前的事务，如果当前没有事务，就抛出异常。 PROPAGATION_REQUIRES_NEW 新建事务，如果当前存在事务，把当前事务挂起。 PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。 极端的传播 PROPAGATION_MANDATORY\n使用外围事务，没有就报错\n话说，这样的代码块为什么不直接写到外围方法里，干嘛新建子方法\n没错就是为了单纯多写一个方法（程序员的事你少管）\nPROPAGATION_NEVER\n该方法无法被事务方法调用，一调就报错。\n懒惰的传播 NOT_SUPPORTED\n管你有没有事务，我就是没有\nSUPPORTS\n你的就是我的，你没有我也没有\n如何触发回滚 该方法向外部抛出了一个异常 回滚是否向外传递 外围方法为 同一事务 ( REQUIRED )，回滚向外传递 外围方法没有try住异常，或者try住之后再次throw，回滚向外传递 （其实就是 外围方法自身触发回滚，本质不是传递） 外围方法是否为父事务(NESTED)，无屌关系 回滚是否向内传递 内部方法为 同一事务 ( REQUIRED )，回滚向内传递 内部方法为 父事务 (NESTED) ，回滚向内传递 REQUIRED （加入事务） 外围方法未开启事务\nPropagation.REQUIRED修饰的内部方法会新开启自己的事务，且开启的事务相互独立，互不干扰。\n外围方法开启事务\nPropagation.REQUIRED修饰的内部方法会加入到外围方法的事务中，所有Propagation.REQUIRED修饰的内部方法和外围方法均属于同一事务，只要一个方法回滚，整个事务均回滚。\nREQUIRES_NEW （新的事务） 外围方法未开启事务\n同 REQUIRED\n外围方法开启事务\nPropagation.REQUIRES_NEW修饰的内部方法依然会单独开启独立事务，且与外部方法事务也独立，内部方法之间、内部方法和外部方法事务均相互独立，互不干扰。\nNESTED （子事务） 外围方法未开启事务\n同 REQUIRED\n外围方法开启事务\nPropagation.NESTED修饰的内部方法属于外部事务的子事务，外围主事务回滚，子事务一定回滚，而内部子事务可以单独回滚而不影响外围主事务和其他子事务\n代码试验\n","permalink":"https://ignoredpjy.github.io/posts/study/spring%E4%BA%8B%E5%8A%A1%E4%BC%A0%E6%92%AD/","summary":"Spring中七种事务传播行为 事务传播行为类型 说明 PROPAGATION_REQUIRED 如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。 PROPAGATION_SUPPORTS 支持当前事务，如果当前没有事务，就以非事务方式执行。 PROPAGATION_MANDATORY 使用当前的事务，如果当前没有事务，就抛出异常。 PROPAGATION_REQUIRES_NEW 新建事务，如果当前存在事务，把当前事务挂起。 PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。 极端的传播 PROPAGATION_MANDATORY\n使用外围事务，没有就报错\n话说，这样的代码块为什么不直接写到外围方法里，干嘛新建子方法\n没错就是为了单纯多写一个方法（程序员的事你少管）\nPROPAGATION_NEVER\n该方法无法被事务方法调用，一调就报错。\n懒惰的传播 NOT_SUPPORTED\n管你有没有事务，我就是没有\nSUPPORTS\n你的就是我的，你没有我也没有\n如何触发回滚 该方法向外部抛出了一个异常 回滚是否向外传递 外围方法为 同一事务 ( REQUIRED )，回滚向外传递 外围方法没有try住异常，或者try住之后再次throw，回滚向外传递 （其实就是 外围方法自身触发回滚，本质不是传递） 外围方法是否为父事务(NESTED)，无屌关系 回滚是否向内传递 内部方法为 同一事务 ( REQUIRED )，回滚向内传递 内部方法为 父事务 (NESTED) ，回滚向内传递 REQUIRED （加入事务） 外围方法未开启事务\nPropagation.REQUIRED修饰的内部方法会新开启自己的事务，且开启的事务相互独立，互不干扰。\n外围方法开启事务\nPropagation.REQUIRED修饰的内部方法会加入到外围方法的事务中，所有Propagation.REQUIRED修饰的内部方法和外围方法均属于同一事务，只要一个方法回滚，整个事务均回滚。\nREQUIRES_NEW （新的事务） 外围方法未开启事务\n同 REQUIRED\n外围方法开启事务\nPropagation.REQUIRES_NEW修饰的内部方法依然会单独开启独立事务，且与外部方法事务也独立，内部方法之间、内部方法和外部方法事务均相互独立，互不干扰。\nNESTED （子事务） 外围方法未开启事务\n同 REQUIRED\n外围方法开启事务","title":"事务传播机制"},{"content":"使用git之前 git 的 配置文件有三个 分别是 system、global、local\nsystem 位于‪C:\\Program Files\\Git\\etc\\gitconfig为所有用户配置文件（linux 系统位于 /etc/gitconfig） global 位于~\\gitconfig 为用户配置文件 local 位于 .\\.git\\gitconfig 为当前项目配置文件 其实还有 --worktree 作用域 : 使用每个工作树的配置文件\n一般，修改 \u0026ndash;global\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 man git config | git config --help # 显示当前作用域的Git配置、附带作用域、附带配置文件位置 $ git config --list| -l --show-scope --show-origin # 直接编辑Git配置文件，不推荐 $ git config -e [--global] # 设置提交代码时的用户信息 git config --global --add user.name \u0026#34;pjy\u0026#34; #--add可省略，删除用 unset git config --global user.email \u0026#34;email\u0026#34; git config --global corlor.ui true #彩色ui git config --global core.editor vim #默认编辑器 git config --global core.ignorecase true #文件名不区分大小写 # 类Unix操作系统使用的是大小写敏感的文件系统， # 而Windows和Mac OS X（默认安装）的文件系统则是大小写不敏感的文件系统。 # README、readme以及Readme文件，在Linux等操作系统上访问的是不同的文件， # 而在Windows和Mac OS X上则指向同一个文件。 # 在Windows和Mac OS X平台上执行git clone后， # 文件会发生覆盖导致丢失 git config --global core.autocrlf input # LF（Unix风格的换行符） CRLF（Windows风格的换行符） # 我们一般希望远程仓库中的代码为LF 所以input，开发环境为win的话，true也行 # core.autocrlf 是一个Git的配置项，它有三个可选值： # true：在checkout时自动将行尾转换为CRLF，在commit时自动将行尾转换为LF。 # input：在检出代码时不自动转换行尾，在提交代码时自动将行尾转换为LF。 # false：在check和commit代码时都不自动转换行尾。 更多配置项详见 官网\n仓库初始化 1 2 3 git init git clone [https|ssh] .gitignore\n基本每个仓库都含有的忽略配置，用来配置 git 忽略哪些目录和文件 ,（git config命令也能配置ignore，不过应该没人这么用）\n常需要忽略一些 集成开发环境配置目录 、 代码打包目录 、日志文件 ，避免多人开发时影响其他人，比如 java配置如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ### MAVEN ### target/ out/ *.class *.jar *.war ### IDE ### .idea/ *.http *.iws *.iml *.ipr .vscode/ .classpath .factorypath .project .settings ### LOG ### *.log *.txt *.temp 查看的命令 常用的一些查看详情的命令，当然使用IDE开发的话，这些命令基本用不到了。\n最常用\n1 2 3 4 5 # 显示有变更的文件 工作区、暂存区、是否发生冲突 $ git status # 显示当前分支的最近几次提交 $ git reflog 代码比较diff\n1 2 3 4 5 6 7 8 9 10 11 # 显示暂存区和工作区的差异 $ git diff # 显示暂存区和上一个commit的差异 $ git diff --cached [file] # 显示工作区与当前分支最新commit之间的差异 $ git diff HEAD # 显示两次提交之间的差异 $ git diff [first-branch]...[second-branch] git log 和 blame\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 显示当前分支的版本历史 $ git log # 显示commit历史，以及每次commit发生变更的文件 $ git log --stat # 搜索提交历史，根据关键词 $ git log -S [keyword] # 显示某个commit之后的所有变动，每个commit占据一行 $ git log [tag] HEAD --pretty=format:%s # 显示某个commit之后的所有变动，其\u0026#34;提交说明\u0026#34;必须符合搜索条件 $ git log [tag] HEAD --grep feature # 显示某个文件的版本历史，包括文件改名 $ git log --follow [file] $ git whatchanged [file] # 显示指定文件相关的每一次diff $ git log -p [file] # 显示过去5次提交 $ git log -5 --pretty --oneline 其他\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 显示所有提交过的用户，按提交次数排序 $ git shortlog -sn # 显示指定文件是什么人在什么时间修改过 $ git blame [file] # 显示今天你写了多少行代码 $ git diff --shortstat \u0026#34;@{0 day ago}\u0026#34; # 显示某次提交的元数据和内容变化 $ git show [commit] # 显示某次提交发生变化的文件 $ git show --name-only [commit] # 显示某次提交时，某个文件的内容 $ git show [commit]:[filename] 奇怪的符号 1 2 3 4 5 6 7 HEAD # 当前分支最新版本 HEAD^^ # 有几个^就是前几个版本 HEAD~[0-n] #数字代替^的个数 git checkout - # - 表示上一次指向的版本，后退操作 git checkout -- . # -- 无意义可省略 ‘.’表示全部文件 origin/ # 远程分支名称的前缀 FETCH_HEAD # 含义见下文 远程同步 提交前的操作（暂存区） 创建、修改 、删除文件\nadd 本质是 同步工作区的变化到暂存区，使暂存区和工作区保持一致。\n当工作区新创建文件 1.txt时，add可以将文件添加到暂存区。之后，如果工作区删除1.txt时，使用add可以将该文件从暂存区也删除。\n1 2 3 4 5 6 7 8 9 10 # 添加当前目录的所有文件到暂存区 git add . # 添加指定文件到暂存区 git add [file1] [file2] ... # 添加指定目录到暂存区，包括子目录 git add [dir] # 添加每个变化前，都会要求确认 # 对于同一个文件的多处变化，可以实现分次提交 git add -p 灵活的删除文件\n1 2 3 4 5 6 # 删除工作区文件，并且将这次删除同步暂存区, # 如果删除时工作区和暂存区文件内容不一致，需要 -f git rm -f [file1] [file2] ... # 暂存区停止追踪指定文件，但该文件会保留在工作区 git rm --cached [file] 重命名文件\n1 2 # 移动或改名文件，并且将这个改名放入暂存区，文件名重复时-f强制 $ git mv -f [file-original] [file-renamed] 提交前的撤销 注意：还原工作区前，确保当前工作区的内容已彻底无用\n工作区 ——》 暂存区\n注意：checkout命令 是 文件内容还原 ，会创建不存在的文件，但不会删除工作区文件，git status 可以看到 那些标红的文件\n本质可以理解为: 将 暂存区文件 复制粘贴到 工作区\n1 2 3 4 # -- 可以省略，推荐省略，有返回结果，加了--就没有，怪 git checkout -- [.|file｜dir] git restore [.|file] #功能完全同上 工作区 ——》 最新版本\n无法单独还原工作区，确实也没必要，工作区还原了，暂存区还有必要保留吗，如果有，为什么不直接还原成暂存区\n暂存区 ——》 最新版本\n1 2 3 4 # --mixed 为默认，可以省略，用于重置暂存区 -\u0026gt; HEAD版本，但不改变工作区，不带[file]则重置全部文件 git reset --mixed HEAD [file] git restore --staged [.|file] #功能完全同上 工作区和暂存区 ——》最新版本\n1 2 3 git checkout HEAD -- [file|dir] # 推荐省略--，理由同上 # restore上面两个指令都用一遍，就行了 结合上面三种来看:\n推荐使用 restore 命令，Git 2.23 版本新引入，相比checkout 表意更清晰。而 reset的实现，则属于是reset的附带功能了\nreset 和 HEAD 一起使用可以做到版本内的撤销操作，但 reset的本职工作是版本的删除回退（危险操作）\n提交后的撤销（版本回退） reset 除了预设的 mixed 模式外，另外还有soft 和hard 模式。欲了解各模式的影响程度，请参照下面的表格。\n模式名称 HEAD的位置 索引 工作目录 指定文件 soft 修改 不修改 不修改 不可 mixed 修改 修改 不修改 可以 hard 修改 修改 修改 不可 安全的回退 ,使用 revert 命令\n相比 reset，revert 不会删除任何提交记录\n假设 版本链：A — B — C— D— E\nreset 回到 C：A — B — C\nrevert回到 C：A — B — C— D— E — C\npush 之前 的 commit 可以用 reset，已push的commit 一定用revert\n因为，本地操作失误的reset，可以用 reflog 抢救\ngit relog（resore补救） 找回已删除的内容\n虽说 Git 是一款强大的版本管理工具，一般来说，提交到代码库的内容不用担心丢失，然而某些特殊情况下仍免不了要做抢救找回，例如不恰当的 reset、错删分支等。这就是 git reflog派上用场的时候了。\n“git reflog”是恢复本地历史的强力工具，几乎可以恢复所有本地记录，例如被 reset 丢弃掉的 commit、被删掉的分支等，称得上代码找回的“最后一根救命稻草”。\n然而需要注意，并非真正所有记录”git reflog”都能够恢复，有些情况仍然无能为力：\n非本地操作的记录 “git reflog”能管理的是本地工作区操作记录，非本地（如其他人或在其他机器上）的记录它就无从知晓了。 未 commit 的内容 例如只在工作区或暂存区被回滚的内容（git checkout – 文件 或 git reset HEAD 文件）。 太久远的内容 “git reflog”保留的记录有一定时间限制（默认 90 天），超时的会被自动清理。另外如果主动执行清理命令也会提前清理掉。 提交操作 1 2 3 4 5 # commit所有 ,携带message $ git commit -am [message] # 覆盖上一次提交并重写message，不会增加提交次数，好用 $ git commit --amend -am [message] 易混淆的checkout 与 restore 、reset 、switch checkout 功能理解: 其实就是查看代码，把代码转移到工作区来查看\n1 2 3 4 5 6 7 8 9 git checkout -- [file] #查看暂存区代码 git checkout [commit_id] file #查看指定版本代码 git checkout -b [branch_name] #查看其他分支代码，也就是切换分支，-b是新建分支并切换 git checkout - #回退到上次查看的版本 git checkout tags/\u0026lt;tag-name\u0026gt; #查看tag版本 因为查看代码会修改工作区，就导致checkout具有撤销工作区的功能\nreset 之前已经讲过，回退版本的功能会修改工作区和暂存区，所以和Head搭配，也具有部分撤销功能\nswitch 和restore 是Git 2.23 版本引入，用来清晰化 checkout 功能类型的新命令。\nswitch: 更清晰地切换分支。\n1 2 3 git switch -c \u0026lt;branch_name\u0026gt; #切换分支 -c 是创建分支 git switch - git switch tags/\u0026lt;tag-name\u0026gt; restore 恢复或撤销文件的更改。\n1 git restore --source=\u0026lt;commit\u0026gt; \u0026lt;file\u0026gt; # restore 也有查看指定版本代码的功能 这两个命令都有 checkout的影子\n分支同步 新建分支，除了上面提到的checkout 和 switch，还有 branch命令\n1 2 3 4 5 git branch [branch_name] git checkout -b [branch_name] git switch -c \u0026lt;branch_name\u0026gt; 删除，重命名分支\n1 2 git branch -d [branch_name] git branch -m [old] [new] 查看所有分支、切换分支\n1 2 3 4 git branch --list -avv # --list 可省略，-a 远程分支，-v 附带id和message ,-vv 再附带与远程分支的对应关系 git checkout [branch_name] origin/\u0026lt;branch_name\u0026gt; # 使用 origin 可以下拉本地没有的远程分支 git switch [branch_name] 合并和冲突\n1 2 3 4 5 git merge [other_branch] # git status 查看冲突在哪个文件 # 手动修改文件 # 用 git add 告诉 Git 文件冲突已经解决 merge 和 rebase\n远程同步 设置远程仓库\n1 2 3 4 5 git remote -v #查看远程仓库 一般会有两个相同url（fetch \u0026amp; push） git remote add [http|ssh] git remote rename git remote remove 设置本地分支与远程分支的对应关系\n1 2 3 4 git branch (--set-upstream-to=\u0026lt;upstream\u0026gt; | -u \u0026lt;upstream\u0026gt;) [\u0026lt;branchname\u0026gt;] git branch --unset-upstream [\u0026lt;branchname\u0026gt;] git push [-u|--set-upstream] \u0026lt;remote\u0026gt; \u0026lt;branch\u0026gt; # push时顺带set git fetch\n无参数默认下拉当前head对应的远程分支，并不会下拉全部分支\ngit pull\ngit pull = git fetch + git merge FETCH_HEAD\npush之前必须pull，push -f也必须先pull\npull 时可能会发生冲突，同 merge操作\ngit push\ngit push -f 操作需要远程仓库关闭分支保护功能\n在本地创建分支来下拉远程的某个分支\n1 2 3 4 5 git checkout -b \u0026lt;branch_name\u0026gt; origin/\u0026lt;branch_name\u0026gt; #等同于 git fetch origin \u0026lt;branch_name\u0026gt; git checkout -b \u0026lt;branch_name\u0026gt; FETCH_HEAD FETCH_HEAD\n在 Git 中，FETCH_HEAD 是一个记录着上次 git fetch 命令所抓取下来的远程分支的快照的引用，也可以被看作是一个指向最新抓取下来的提交的指针。\n当你使用 git fetch 命令从远程仓库拉取最新的代码时，Git 会把最新的提交记录保存在本地的 FETCH_HEAD 引用中。此时，你可以使用 git merge FETCH_HEAD 命令将本地分支合并到 FETCH_HEAD 所指向的最新提交。\n需要注意的是，FETCH_HEAD 引用只会在下一次执行 git fetch 命令时被更新。如果你希望在当前分支中使用最新的提交记录，你需要先执行 git fetch 命令来更新 FETCH_HEAD，然后再使用 git merge FETCH_HEAD 命令来合并最新的提交记录。\ngit prune\n清理远程分支在本地的存档，与fetch操作相反，不常用，解决fetch报错\ntag标签 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # 列出所有tag $ git tag # 新建一个tag在当前commit $ git tag [tag] # 新建一个tag在指定commit $ git tag [tag] [commit] # 删除本地tag $ git tag -d [tag] # 删除远程tag $ git push origin :refs/tags/[tagName] # 查看tag信息 $ git show [tag] # 提交指定tag $ git push [remote] [tag] # 提交所有tag $ git push [remote] --tags # 新建一个分支，指向某个tag $ git checkout -b [branch] [tag] squach 在开发一个功能的时候会反复的提交代码，会造成一个功能有很多次提交，在我们要向master做分支合并的时候，就会出现很多commits，在合并以后同一个功能的commits就会很多，导致我们无法清晰的知道这个功能关联的commit有哪些，这个squash就是优化我们的commits信息，让我们的版本仓库看起来简洁明了，功能点一目了然。\n使用比较简单，比如我想将本地开发分支的内容合并到master主线分支上，并且期望将一个功能的所有提交压缩成一个commit；\n有两种方法可以实现 Git 压缩：\ngit rebase -i 作为用于压缩提交的交互式工具 git merge -squash 在合并时使用 -squash 选项 使用 git rebase -i\n先checkout master分支并做本地分支和远程仓库同步\n1 2 git checkout master git pull （一定要做同步，若本地代码和远端仓库不同步的话，就会出现很多远端的修改进入我们的squash时的commits当中）\n切换到开发分支 dev ， 并执行commits合并操作\n1 2 3 4 5 6 7 8 9 10 11 12 13 git checkout dev git rebase -i master # 执行上面的语句后，会进入以下编辑界面 pick xxx: commit1 add : add xxx pick xxx: commit2 fix: update xxxx pick xxx: commit3 fix: delete xxx pick xxx: commit4 modify : update xxxx # 进入编辑模式，将除第一行的pick外，其余的pick都改成 squash（或 s）， # 退出编辑模式，保存即可 pick xxx: commit1 add : add xxx squash xxx: commit2 fix: update xxxx squash xxx: commit3 fix: delete xxx squash xxx: commit4 modify : update xxxx 以上操作顺利的话，我们执行以下操作即可：\ngit push -f 注意：squash操作后你的提交信息就变成了一次提交，会记录你之前的提交的描述信息，但是已经看不到相关的提交记录了；\n看了资料以后，git 在merge的时候提供了这种squash merge的操作方式，未有实践，这里也做个记录：\n1 2 git checkout master git merge --squash dev 这样可以在master节点上只看到一个提交，不管你在dev分支上有多少次提交\n使用 git merge -squash 压缩 Git 提交\n以下是将分支与当前分支（通常是 main）合并并压缩源分支的提交的命令语法。\n1 git merge --squash \u0026lt;source_branch_name_to_squash\u0026gt; 我们现在将合并功能分支即。feature1 与 main 分支一起压缩。\n首先，我们将切换到 master 分支。\n1 2 $ git checkout main Switched to branch \u0026#39;main\u0026#39; 然后，我们将使用 squash 选项执行 git merge，如下所示。\n1 2 3 $ git merge --squash feature1 Squash commit -- not updating HEAD Automatic merge went well; stopped before committing as requested 当我们使用 \u0026ndash;squash 选项执行 merge 时，Git 不会像在正常合并中那样在目标分支中创建合并提交。相反，Git 接受源分支中的所有更改。feature1 并将其作为本地更改放入目标分支即 master 的工作副本中。\n请参阅下文。\n1 2 3 4 5 $ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: config.ini 在这里，文件 config.ini 在 feature1 分支中进行了更改。\n现在，剩下的就是将更改提交到 main 分支，如下所示。\n1 2 3 $ git commit -am \u0026#39;Merged and squashed the feature1 branch changes\u0026#39; [main 573b923] Squashed and merged the feature1 branch 1 file changed, 4 insertions(+) 因此，我们现在已将 feature1 分支中的更改合并到 main 分支，同时压缩了 feature1 分支的提交消息。我们现在在 main 分支中只有一条提交消息。\nstarch 1 2 3 git stash git pull git stash pop| git stash apply git stash pop 命令会在 stash 应用之后丢弃（默认情况下指的是最顶部的）stash，而 git stash apply 会将其保留在存储列表中，以备日后重用（或者您可以在之后使用 git stash drop 命令移除此 stash）。\n除非 git stash pop 之后存在冲突，在这种情况下，它将不会删除该 stash，而使其行为与git stash apply 的命令完全相同。\n我们也可以使用另一种方式来实现 git stash pop，那就是：git stash apply \u0026amp;\u0026amp; git stash drop。\n到这我们基本实现了上述需求，但还需要知道一些基本的 git stash 知识，方便我们更清楚的操作。\n下列命令可以查看缓存的列表：\n1 2 git stash list 复制代码 有时我们会发现因冲突导致 git stash pop 命令并没有消除 list 的记录，这样对我们操作造成一些干扰，这时我我们可以执行以下操作，清除记录：\n1 git stash drop 我们还可以对缓存的代码进行标识，方便查看：\n1 git stash save [stashMessage] 当缓存了很多条记录的时候，我们还可以一键清除：\n1 git stash clear cherry-pick git cherry-pick命令的作用，就是将指定的提交（commit）应用于其他分支。\n1 2 3 4 5 6 7 8 #某提交应用于当前分支 git cherry-pick [commitHash] #多个提交 git cherry-pick \u0026lt;HashA\u0026gt; \u0026lt;HashB\u0026gt; #上面的命令可以转移从 A 到 B 的所有提交。它们必须按照正确的顺序放置：提交 A 必须早于提交 B，否则命令将失败，但不会报错。 git cherry-pick A..B #注意，使用上面的命令，提交 A 将不会包含在 Cherry pick 中。如果要包含提交 A，可以使用下面的语法。 git cherry-pick A^..B 如果操作过程中发生代码冲突，Cherry pick 会停下来，让用户决定如何继续操作。\n（1）--continue\n用户解决代码冲突后，第一步将修改的文件重新加入暂存区（git add .），第二步使用下面的命令，让 Cherry pick 过程继续执行。\n1 $ git cherry-pick --continue （2）--abort\n发生代码冲突后，放弃合并，回到操作前的样子。\n（3）--quit\n发生代码冲突后，退出 Cherry pick，但是不回到操作前的样子。\nworktree 比 starch命令更强大\n仅需维护一个 repo，又可以同时在多个 branch 上工作，互不影响\n1 2 3 4 git worktree add [-f] [--detach] [--checkout] [--lock] [-b \u0026lt;new-branch\u0026gt;] \u0026lt;path\u0026gt; [\u0026lt;commit-ish\u0026gt;] git worktree list [--porcelain] git worktree remove [-f] \u0026lt;worktree\u0026gt; git worktree prune [-n] [-v] [--expire \u0026lt;expire\u0026gt;] 在展开说明之前，需要和大家普及两个你可能忽视的 Git 知识点：\n默认情况下， git init 或 git clone 初始化的 repo，只有一个 worktree，叫做 main worktree\n在某一个目录下使用 Git 命令，当前目录下要么有 .git 目录；\n要么有 .git 文件，而 .git 文件，里面的内容必须是指向 .git 文件夹的，可以理解为一个 link\ngit worktree add\n1 git worktree add ../worktrees/[分支名] 在当前项目目录的父目录新建文件夹 worktrees，创建[分支名]项目\ncd /worktrees/[分支名] 会发现，这个分支下并不存在 .git 文件夹，却存在一个 .git 文件，打开文件，内容如下：\n1 gitdir: /Users/../test/.git/worktrees/[分支名] 接下来，你就可以在 feature2 分支上做一切你想做的内容了(add/commit/pull/push)，和 main worktree 互不干扰\n如果 [分支名]分支名称带 “/” 目录分割符，需要-b参数 指定分支名称，防止生成多余嵌套的目录\n1 git worktree add -b \u0026#34;hotfix/JIRA234-fix-naming\u0026#34; ../hotfix/JIRA234-fix-naming git worktree list\n所有的worktree 都在共用一个 repo，所以在任意一个 worktree 目录下，都可以执行如下命令来查看 worktree 列表\n执行完命令后，可以查看到我们上面创建的所有 worktree 信息, main worktree 也会显示在此处\nworktree 的工作做完了，也是要及时删除的，否则也会浪费很多磁盘空间\ngit worktree remove\n这个命令很简单了，worktree 的名字叫什么，直接就 remove 什么就好了\n假设你创建一个 worktree，并在里面有改动，突然间这个worktree 又不需要了，此刻你按照上述命令是不能删掉了，此时就需要 -f 参数来帮忙了\n删除了 worktree，其实在 Git 的文件中，还有很多 administrative 文件是没有用的，为了保持清洁，我们还需要进一步清理\ngit worktree prune\n这个命令就是清洁的兜底操作，可以让我们的工作始终保持整洁\nSubtree 与 Submodule subtree 和 submodule 的目的都是用于 git 子仓库管理，二者的主要区别在于，subtree 属于拷贝子仓库，而 submodule 属于引用子仓库。\nSubtree vs Submodule\n维度 subtree submodule 优劣对比 空间占用 subtree 在初始化 add 时，会将子仓库 copy 到父仓库中，并产生至少一次 merge 记录。所以会占用大量父仓库空间 submodule 在初始化 add 时，会在父仓库新建一个 .gitmodules 文件，用于保存子仓库的 commit hash 引用。所以不会占用父仓库空间 submodule 更优 clone subtree add 至父仓库之后，后续的 clone 操作与单一仓库操作相同 后续 clone 时 submodule 还需要 init/update 操作，且 submodule 子仓库有自己的分支 subtree 更优 update 子仓库更新后，父仓库需要 subtree pull 操作，且命令行略长，需要指定 \u0026ndash;prefix 参数。由于无法感知子仓库的存在，可能会产生 merge 冲突需要处理 子仓库更新后，父仓库需要 submodule update 操作。父仓库只需变动子仓库 hash 引用，不会出现冲突 submodule 更优 commit 父仓库直接提交父子仓库目录里的变动。若修改了子仓库的文件，则需要执行 subtree push 父子仓库的变动需要单独分别提交。且注意先提交子仓库再提交父仓库 subtree 更优 Subtree 命令行简化\nsubtree 在操作时，命令行较长，可以使用 remote 配置简化，例如\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 以下为标准 subtree add 命令行示例 git subtree add --prefix=centos-config --squash git@github.com:kaiye/centos-config.git master # 可以简化为 # 1. 先为远程子仓库配置一个别名，便于后续的 pull 与 push 操作，这里例子以 centos 为别名 git remote add centos git@github.com:kaiye/centos-config.git # gra centos ... # 2. 其中 --prefix= 简写为 -P，配置 --squash 表示不拉取子仓库的历史提交记录 git subtree add -P centos-config --squash centos master # 后续更新子仓库可以使用 git subtree pull -P centos-config centos master # 若发生 fatal: refusing to merge unrelated histories 报错，加上 --squash 参数即可 git submodule update 出错解决方案\n假如在执行 git submodule update 时出现以下类似错误信息：\n1 2 fatal: reference is not a tree: f869da471c5d8a185cd110bbe4842d6757b002f5 Unable to checkout \u0026#39;f869da471c5d8a185cd110bbe4842d6757b002f5\u0026#39; in submodule path \u0026#39;centos-config\u0026#39; 发生错误的原因是，centos-config 子仓库在某电脑 A 的「本地」commit 了新的版本 「f869da471c5d8a185cd110bbe4842d6757b002f5」，且该次 commit 未 push origin。但其父级仓库中引用了该子仓库的版本号，且将引用记录 push origin，导致其他用户无法 update 。\n解决方案是，在电脑 A 上将子仓库 push origin 后，在其他客户机上执行 git submodule update 。或者使用 git reset，将子仓库的引用版本号还原成 origin 上存在的最新版本号。\n","permalink":"https://ignoredpjy.github.io/posts/study/git%E6%8C%87%E5%8D%97/","summary":"使用git之前 git 的 配置文件有三个 分别是 system、global、local\nsystem 位于‪C:\\Program Files\\Git\\etc\\gitconfig为所有用户配置文件（linux 系统位于 /etc/gitconfig） global 位于~\\gitconfig 为用户配置文件 local 位于 .\\.git\\gitconfig 为当前项目配置文件 其实还有 --worktree 作用域 : 使用每个工作树的配置文件\n一般，修改 \u0026ndash;global\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 man git config | git config --help # 显示当前作用域的Git配置、附带作用域、附带配置文件位置 $ git config --list| -l --show-scope --show-origin # 直接编辑Git配置文件，不推荐 $ git config -e [--global] # 设置提交代码时的用户信息 git config --global --add user.","title":"Git指南"}]